{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import importlib.util\n",
    "sys.path.append('/home/biodb/data/abio_database_pipeline/')\n",
    "from pipeline.datasets_curation import datasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatCompiler():\n",
    "    \n",
    "    def __init__(self, input_number = None, part = None, output_number = None,\n",
    "                 input_dir = '/home/biodb/data/dataset_collection/datasets/3_standard_dataset',\n",
    "                 output_dir = '/home/biodb/data/dataset_collection/datasets/5_Pfizer_format/R2'):\n",
    "        \n",
    "        self.input_number = input_number\n",
    "        self.output_number = output_number\n",
    "        self.part = part\n",
    "        self.input_dir = input_dir + '/' + input_number + '/' + part\n",
    "        self.output_dir = output_dir + '/' + output_number + '/' + part\n",
    "        \n",
    "        self.unstructured_data_dir =  self.input_dir + '/processed_data' + '/unstructuredData.json'\n",
    "        self.cell_anno_dir = self.input_dir + '/processed_data' + '/cellAnnotation.tsv'\n",
    "        self.gene_anno_dir = self.input_dir + '/processed_data' + '/geneAnnotation.tsv'\n",
    "        self.exp_raw_dir = self.input_dir + '/processed_data' + '/expressionMatrix_rawCounts.tsv'\n",
    "        self.exp_tpm_dir = self.input_dir + '/processed_data' + '/expressionMatrix_TPM.tsv'\n",
    "        self.exp_normalized_dir = self.input_dir + '/processed_data' + '/expressionMatrix_normalized.tsv'\n",
    "        self.diff_genes_dir = self.input_dir + '/processed_data' + '/Diff_genes.json'\n",
    "        \n",
    "        self.metadata_dir = self.output_dir + '/metadata.tsv'\n",
    "        self.phenotype_dir = self.output_dir + '/phenotype.tsv'\n",
    "        self.geneID_dir = self.output_dir + '/geneID.tsv'\n",
    "        self.cellID_dir = self.output_dir + '/cellID.tsv'\n",
    "        self.marker_genes_dir = self.output_dir + '/markerGenes.tsv'\n",
    "        self.ontology_dir =  self.output_dir + '/ontologyMapping.tsv'\n",
    "    \n",
    "    def making_dir(self):\n",
    "        try:\n",
    "            os.system(\"mkdir -p \" + self.output_dir)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def transform_format(self):\n",
    "        \n",
    "        self.making_dir()\n",
    "        self.transform_phenotype()\n",
    "        self.transform_marker_genes()\n",
    "        self.transform_ontology()\n",
    "        self.transform_geneID()\n",
    "        self.transform_metadata()\n",
    "        \n",
    "        return_message = 'successfully'\n",
    "        return return_message\n",
    "    \n",
    "    def transform_metadata(self):\n",
    "        \n",
    "        with open(self.unstructured_data_dir, 'r') as json_file:\n",
    "            meta = json.load(json_file)['metadata']\n",
    "    \n",
    "        with open(self.exp_normalized_dir, 'r') as file:\n",
    "            x = file.readline()\n",
    "            x = file.readline()\n",
    "            normalized_method = x.split('\\t')[0]\n",
    "        \n",
    "        metadata = dict()\n",
    "        list_names = ['datasetID','title','accessionNumber','abstract','source','sourceID','numberOfCells','libraryPreparationMethod',\n",
    "                      'sequencingPlatform','pubmedID','clusteringMethod','biomarkerDerivationMethod','fastqURL','genomeBuild','annotation',\n",
    "                      'subDataset','description','tissue']\n",
    "        for i in list_names:\n",
    "            metadata[i] = meta[i]\n",
    "        metadata['datasetID'] = self.output_number+'_'+self.part\n",
    "        metadata['normalizationMethod'] = normalized_method\n",
    "        metadata = pd.DataFrame(pd.Series(metadata)).T\n",
    "#         metadata = pd.DataFrame(metadata, index = [0])\n",
    "        metadata.replace('notAvailable','',inplace = True)\n",
    "        metadata.replace('NA','',inplace = True)\n",
    "        metadata = metadata.fillna('')\n",
    "        metadata.to_csv(self.metadata_dir ,sep = '\\t',index = False)\n",
    "            \n",
    "        return_message = 'successfully generated Metadata.tsv'\n",
    "        return return_message\n",
    "    \n",
    "    def transform_phenotype(self):\n",
    "        \n",
    "        df_cell = pd.read_csv(self.cell_anno_dir ,sep='\\t')\n",
    "        if \"clusteringMethod\" in df_cell.columns.tolist():\n",
    "            self.cluster = False\n",
    "            df_cell = df_cell.drop(['clusteringMethod'],axis=1)\n",
    "            df_cell['clusterID'] = \"\"\n",
    "            df_cell['clusterName'] = \"\"\n",
    "        else:\n",
    "            self.cluster = True\n",
    "        try:\n",
    "            df_cell = df_cell.drop(['clusterName_scibet'],axis=1)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            df_cell = df_cell.drop(['meta_scibetHCL'],axis=1)\n",
    "        except:\n",
    "            pass                           \n",
    "        df_cell = df_cell.drop(['cellOntologyName','cellOntologyID','FACSMarker'], axis=1)\n",
    "        \n",
    "        df_cell['filtered'] = True\n",
    "        if os.path.getsize(self.exp_raw_dir) > 100:\n",
    "            cell_raw = []\n",
    "            with open(self.exp_raw_dir, 'r') as file:\n",
    "                x = file.readline()\n",
    "                while True:\n",
    "                    x = file.readline()\n",
    "                    if x == '':\n",
    "                        break\n",
    "                    else: \n",
    "                        cell_raw.append(x.split('\\t')[0])\n",
    "        \n",
    "            if len(cell_raw) != cell_anno.shape[0]:\n",
    "                cell = pd.DataFrame()\n",
    "                cell['cellID'] = cell_raw\n",
    "                df_cell = cell.merge(df_cell, how = 'left', sort = False)\n",
    "                df_cell['filtered'] = df_cell['filtered'].fillna(False).tolist()\n",
    "            else:\n",
    "                df_cell['filtered'] = False\n",
    "                \n",
    "        df_cell.replace('notAvailable','',inplace = True)\n",
    "        df_cell = df_cell.fillna('')\n",
    "        df_cell.to_csv(self.phenotype_dir ,sep = '\\t',index = False)\n",
    "        return_message = 'successfully generated phenotype.tsv'\n",
    "        return return_message\n",
    "    \n",
    "    def transform_marker_genes(self):\n",
    "        \n",
    "        if self.cluster == False:\n",
    "            pass\n",
    "        else:\n",
    "            my_builder = datasetBuilder.DatasetBuilder(starting_dir=self.input_dir)\n",
    "            with open(self.diff_genes_dir, 'r') as json_file:\n",
    "                markers= json.load(json_file)['wilcoxon']\n",
    "            cluster = [x for x in markers]\n",
    "            marker_genes = pd.DataFrame()\n",
    "            for x in range(0,len(cluster)):\n",
    "                z = pd.DataFrame(markers[cluster[x]])\n",
    "                logfc = z['logFC'].tolist()\n",
    "                k = [i > 0 for i in logfc]\n",
    "                z = z.loc[k,]\n",
    "                z = z.iloc[:100,:]\n",
    "                z = z.drop(columns= ['logFC','qValue'])\n",
    "                z.insert(1,\"ensemblID\",my_builder.calculate_ensemblID(gene=z['geneSymbol'].tolist()))\n",
    "                z['statisticsType'] = 'wilcoxon'\n",
    "                z['clusterName'] = cluster[x]\n",
    "                \n",
    "                marker_genes = marker_genes.append(z, ignore_index = True)\n",
    "            \n",
    "            marker_genes.replace('notAvailable','',inplace = True)\n",
    "            marker_genes.to_csv(self.marker_genes_dir, sep = '\\t', index = False)   \n",
    "\n",
    "            return_message = 'successfully generated Marker_genes.tsv'\n",
    "            return return_message\n",
    "        \n",
    "    def transform_geneID(self):\n",
    "        \n",
    "        my_builder = datasetBuilder.DatasetBuilder(starting_dir=self.input_dir)\n",
    "        gene_anno = pd.read_csv(self.gene_anno_dir, sep = '\\t')\n",
    "        genes = pd.DataFrame(gene_anno.iloc[:,:2])\n",
    "        genes.replace('notAvailable' or 'NA','',inplace = True)\n",
    "        genes['filtered'] = False\n",
    "        with open(self.exp_raw_dir, 'r') as file:\n",
    "            x = file.readline()[:-1]\n",
    "        gene_raw = x.split('\\t')[1:]\n",
    "        with open(self.exp_normalized_dir, 'r') as file:\n",
    "            y = file.readline()[:-1]\n",
    "        gene_norm = y.split('\\t')[2:]\n",
    "        if gene_norm[0] == 'geneSymbol1':\n",
    "            pass\n",
    "        elif gene_raw[0] == 'geneSymbol1':\n",
    "            genes['filtered'] = True\n",
    "        elif len(gene_raw) != genes.shape[0]:\n",
    "            filtered = [x in gene_norm for x in gene_raw]\n",
    "            genes = pd.DataFrame()\n",
    "            genes['geneSymbol'] = gene_raw\n",
    "            genes['ensemblID'] = my_builder.calculate_ensemblID(gene=gene_raw)\n",
    "            genes['filered'] = filtered\n",
    "        elif len(gene_raw) == genes.shape[0]:\n",
    "            genes['filtered'] = True\n",
    "            \n",
    "        genes.to_csv(self.geneID_dir ,sep = '\\t',index = False)\n",
    "        \n",
    "        return_message = 'successfully generated geneID.tsv'\n",
    "        return return_message\n",
    "        \n",
    "        \n",
    "    def transform_ontology(self):\n",
    "        \n",
    "        cell_anno = pd.read_csv(self.cell_anno_dir ,sep='\\t')\n",
    "        if self.cluster == False:\n",
    "            cell_anno['clusterID'] = \"\"\n",
    "            cell_anno['clusterName'] = \"\"\n",
    "        onto = cell_anno[['clusterID','clusterName','cellOntologyName','cellOntologyID']]\n",
    "        ontology = onto.drop_duplicates()\n",
    "        ontology.replace('notAvailable','',inplace = True)\n",
    "        ontology = ontology.fillna('')\n",
    "        if not set(ontology['cellOntologyName']) == {''}:\n",
    "            ontology.to_csv(self.ontology_dir, sep = '\\t',index = False)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        return_message = 'successfully generated Ontology_mapping.tsv'\n",
    "        return return_message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'successfully generated Metadata.tsv'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genentech_format = FormatCompiler(input_number = \"No_3\", part = \"part_2\", output_number = \"No_3\",\n",
    "                                  output_dir = '/home/biodb/data/dataset_collection/datasets/4_genentech_format')\n",
    "genentech_format.transform_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/home/biodb/data/dataset_collection/datasets/4_genentech_format/No_3/part_2/metadata.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dict()\n",
    "y['tissue'] = x['tissue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head', 'neck']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "literal_eval(y['tissue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path = '/home/biodb/data/dataset_collection/datasets/3_standard_dataset/No_10/part_1/processed_data/Diff_genes.json'\n",
    "with open(path, 'r') as json_file:\n",
    "    markers= json.load(json_file)['wilcoxon']\n",
    "cluster = [x for x in markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "z = pd.DataFrame(markers[cluster[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfc = z['logFC'].tolist()\n",
    "k = [i > 0 for i in logfc]\n",
    "z = z.loc[k,]\n",
    "z = z.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(cluster)):\n",
    "    z = pd.DataFrame(markers[cluster[x]])\n",
    "    logfc = z['logFC'].tolist()\n",
    "    k = [i > 0 for i in logfc]\n",
    "    z = z.loc[k,]\n",
    "    z = z.iloc[:100,:]\n",
    "    z = z.drop(columns= ['logFC','qValue'])\n",
    "#     z.insert(1,\"ensemblID\",my_builder.calculate_ensemblID(gene=z['geneSymbol'].tolist()))\n",
    "    z['statisticsType'] = 'wilcoxon'\n",
    "    z['clusterName'] = cluster[x]\n",
    "\n",
    "    marker_genes = marker_genes.append(z, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_raw = []\n",
    "path = '/home/biodb/data/dataset_collection/datasets/3_standard_dataset/No_10/part_1/processed_data/expressionMatrix_rawCounts.tsv'\n",
    "with open(path, 'r') as file:\n",
    "    x = file.readline()\n",
    "    while True:\n",
    "        x = file.readline()\n",
    "        if x == '':\n",
    "            break\n",
    "        else: \n",
    "            cell_raw.append(x.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as file:\n",
    "    x = file.readline()\n",
    "    x = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B1_AAACATTGTTTGGG_Enterocyte.Immature.Distal'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split('\\t')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7216"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cell_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
